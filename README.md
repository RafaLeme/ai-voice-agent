# ü§ñ AI Voice Agent para SDR (Sales Development Representative)

Um AI Voice Agent completo e inteligente, incialmente focado em otimizar a prospec√ß√£o de clientes para SDRs (Sales Development Representatives). Desenvolvido com Python (FastAPI) no backend e um frontend simples em HTML, CSS e JavaScript, este agente √© capaz de interagir por voz, transcrever a fala, consultar uma base de conhecimento contextual (RAG) e gerar respostas faladas, adaptando-se ao seu neg√≥cio.

## ‚ú® Funcionalidades Principais (MVP)

* **Intera√ß√£o por Voz**: Capta√ß√£o de √°udio diretamente do navegador.
* **Speech-to-Text (STT)**: Transcri√ß√£o da fala do usu√°rio para texto utilizando a API Whisper da OpenAI.
* **Retrieval-Augmented Generation (RAG)**: Gera√ß√£o de respostas contextuais e relevantes utilizando a base de conhecimento da empresa (cat√°logo de produtos, FAQs, etc.) com Langchain e um √≠ndice FAISS.
* **Large Language Model (LLM)**: Utiliza o `gpt-4o-mini` da OpenAI para gerar respostas inteligentes e com persona de SDR.
* **Text-to-Speech (TTS)**: Convers√£o da resposta do agente para √°udio utilizando `gTTS`.
* **Comunica√ß√£o Bidirecional**: Intera√ß√£o em tempo real via WebSockets entre frontend e backend.

## üöÄ Como Rodar o Projeto

Siga os passos abaixo para configurar e executar o projeto localmente.

### Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

* **Python 3.9+**: [Download Python](https://www.python.org/downloads/)
* **Git**: [Download Git](https://git-scm.com/downloads)
* **FFmpeg**: Essencial para a convers√£o de √°udio no backend.
    * **Windows**: Baixe a vers√£o `gpl` ou `lgpl` do [site oficial (Windows builds)](https://ffmpeg.org/download.html). Extraia o conte√∫do e adicione o caminho da pasta `bin` do FFmpeg √†s vari√°veis de ambiente do sistema (`Path`).
    * **Linux (Debian/Ubuntu)**: `sudo apt update && sudo apt install ffmpeg`
    * **macOS (com Homebrew)**: `brew install ffmpeg`
    * **Verifica√ß√£o**: Abra um novo terminal e digite `ffmpeg -version`. Deve exibir informa√ß√µes da vers√£o.

### Configura√ß√£o e Execu√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone <URL_DO_SEU_REPOSITORIO>
    cd ai-voice-sdr-agent # Ou o nome da sua pasta raiz
    ```

2.  **Crie e Ative o Ambiente Virtual:**
    √â altamente recomendado usar um ambiente virtual para isolar as depend√™ncias do projeto.
    ```bash
    python -m venv venv
    ```
    * **Windows:**
        ```bash
        .\venv\Scripts\activate
        ```
    * **Linux/macOS:**
        ```bash
        source venv/bin/activate
        ```
    (Voc√™ ver√° `(venv)` no in√≠cio da sua linha de comando, indicando que o ambiente est√° ativo.)

3.  **Instale as Depend√™ncias do Backend:**
    Certifique-se de que seu ambiente virtual esteja ativo antes de executar este comando.
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure suas Vari√°veis de Ambiente:**
    * No diret√≥rio `backend/`, crie um arquivo chamado `.env`.
    * Dentro deste arquivo `.env`, adicione sua chave da API da OpenAI. **Substitua `sua_chave_aqui` pela sua chave real.**
        ```
        OPENAI_KEY="sk-sua_chave_aqui"
        ```
    * **Mantenha este arquivo `.env` fora do controle de vers√£o do Git (ele j√° est√° no `.gitignore`).**

5.  **Prepare a Base de Conhecimento (RAG):**
    * No diret√≥rio `backend/data/`, adicione arquivos com conteudos para o RAG em  `.txt` preferencialmente, com o conte√∫do que voc√™ deseja que o agente utilize para suas respostas (informa√ß√µes sobre produtos, servi√ßos, FAQs, etc.). Quanto mais detalhado e relevante, melhor.
    * Com o ambiente virtual ativo, construa o √≠ndice FAISS a partir do seu `CatalogoProdutos.txt`. Este √≠ndice ser√° usado para o RAG.
        ```bash
        cd backend
        python -c "from rag import build_index; build_index()"
        cd .. # Volte para a raiz do projeto
        ```
        Voc√™ ver√° a mensagem `[RAG] √çndice salvo em: faiss_index` no console.

6.  **Inicie o Servidor Backend (FastAPI):**
    Abra um terminal, ative seu ambiente virtual e execute o Uvicorn na raiz do projeto:
    ```bash
    (venv) python -m uvicorn backend.main:tapp --reload --host 0.0.0.0 --port 8000
    ```
    Mantenha este terminal aberto. O servidor estar√° dispon√≠vel em `http://localhost:8000`.

7.  **Inicie o Servidor Frontend:**
    Abra um **segundo terminal**, e **N√ÉO ative o ambiente virtual neste terminal**, pois o servidor HTTP Python √© um utilit√°rio de sistema. Navegue at√© a pasta `frontend/public`:
    ```bash
    cd frontend/public
    ```
    Ent√£o, inicie o servidor HTTP simples:
    ```bash
    python -m http.server 3000
    ```
    Mantenha este terminal aberto. O frontend estar√° dispon√≠vel em `http://localhost:3000`.

8.  **Acesse a Aplica√ß√£o:**
    Abra seu navegador web e acesse:
    ```
    http://localhost:3000
    ```

## üé§ Como Usar (MVP)

1.  Com a p√°gina aberta em `http://localhost:3000`, clique no bot√£o **"Iniciar"**.
2.  Se o navegador solicitar permiss√£o para usar o microfone, **conceda a permiss√£o**.
3.  Fale claramente no microfone, fazendo uma pergunta relacionada ao conte√∫do que voc√™ inseriu no `CatalogoProdutos.txt`.
4.  Clique no bot√£o **"Parar"**.
5.  O agente processar√° seu √°udio e, ap√≥s alguns segundos, voc√™ ouvir√° a resposta sintetizada pelo agente diretamente no navegador.

## üõ†Ô∏è Tecnologias Utilizadas

* **Backend**: Python 3.x, FastAPI, Uvicorn
* **Frontend**: HTML, CSS, JavaScript (Vanilla JS para o core)
* **STT (Speech-to-Text)**: OpenAI Whisper API
* **LLM (Large Language Model)**: OpenAI GPT-4o-mini
* **RAG (Retrieval-Augmented Generation)**: Langchain, FAISS (para √≠ndice vetorial)
* **TTS (Text-to-Speech)**: gTTS
* **Manipula√ß√£o de √Åudio**: `pydub` (requer FFmpeg)
* **Vari√°veis de Ambiente**: `python-dotenv`
* **Comunica√ß√£o**: WebSockets

## üõ£Ô∏è Pr√≥ximos Passos e Melhorias Futuras

* **Integra√ß√£o com VOIP e Asterisk**: Conectar a solu√ß√£o a um n√∫mero VOIP real atrav√©s do Asterisk hospedado em Docker.
* **Streaming de √Åudio Cont√≠nuo**: Implementar grava√ß√£o e processamento de √°udio em tempo real para uma conversa√ß√£o mais fluida, sem a necessidade de clicar "Iniciar/Parar" para cada turno.
* **Gerenciamento de Contexto da Conversa**: Adicionar mem√≥ria √† intera√ß√£o para que o agente possa manter o contexto em di√°logos mais longos.
* **Feedback Visual no Frontend**: Melhorar a experi√™ncia do usu√°rio com indicadores visuais de grava√ß√£o, processamento e reprodu√ß√£o.
* **Modulariza√ß√£o do RAG**: Refinar a estrutura de dados e as estrat√©gias de recupera√ß√£o para RAG.
* **Testes Abrangentes**: Expandir a su√≠te de testes para cobrir mais cen√°rios e componentes da aplica√ß√£o.

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Se voc√™ tiver ideias, melhorias ou encontrar bugs, sinta-se √† vontade para abrir uma issue ou enviar um Pull Request.

---